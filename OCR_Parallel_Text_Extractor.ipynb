{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayuathm/Job_matching_Analysis_AI_SSD/blob/main/OCR_Parallel_Text_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a1f6148",
      "metadata": {
        "id": "7a1f6148"
      },
      "source": [
        "# 📄 OCR-Enabled Parallel Text Extraction in Colab\n",
        "This notebook extracts text from PDFs and DOCX files using PyMuPDF, pytesseract (for scanned documents), and docx2txt. It uses parallel processing with batching, timeouts, and checkpointing to efficiently handle large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5CF7r4ugXw4q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CF7r4ugXw4q",
        "outputId": "82bf4133-2cd8-4d9c-aea4-aee851d2692f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pymupdf-1.26.1-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: docx2txt, pytesseract, pymupdf, pdf2image\n",
            "Successfully installed docx2txt-0.9 pdf2image-1.17.0 pymupdf-1.26.1 pytesseract-0.3.13\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 0s (445 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126319 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "# 📦 Install required libraries\n",
        "!pip install pymupdf pytesseract docx2txt pdf2image tqdm\n",
        "# ✅ Install Tesseract OCR backend (optional but recommended)\n",
        "!apt-get install -y poppler-utils tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "OmMX4slwXrMy",
      "metadata": {
        "id": "OmMX4slwXrMy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import pytesseract\n",
        "import docx2txt\n",
        "import pandas as pd\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed, TimeoutError\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "AI1UYOTEYPBZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI1UYOTEYPBZ",
        "outputId": "56e90079-b283-4c8f-9231-7abddd8cc6d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ✅ Step 2: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "vmbcJnWPYHwz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmbcJnWPYHwz",
        "outputId": "61312f7f-afec-48af-9ab6-66faef76e090"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📦 Total files found: 1382\n",
            "🚀 Processing batch 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [2:37:34<00:00, 18.91s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 Checkpoint saved for batch 1\n",
            "🚀 Processing batch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [2:55:58<00:00, 21.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Checkpoint saved for batch 2\n",
            "🚀 Processing batch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 382/382 [1:54:20<00:00, 17.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Checkpoint saved for batch 3\n",
            "✅ Extraction complete. Final CSV saved to: /content/drive/MyDrive/extracted_batch6.csv\n"
          ]
        }
      ],
      "source": [
        "# 📁 Path to attachments\n",
        "attachments_folder = \"/content/drive/MyDrive/batch6\"\n",
        "output_file = \"/content/drive/MyDrive/extracted_batch6.csv\"\n",
        "checkpoint_file = \"/content/checkpoint.csv\"\n",
        "\n",
        "# 🧠 OCR-aware PDF extractor\n",
        "def extract_text_from_pdf(file_path):\n",
        "    try:\n",
        "        with fitz.open(file_path) as doc:\n",
        "            text = \"\\n\".join([page.get_text() for page in doc if page.get_text().strip()])\n",
        "        if text.strip():\n",
        "            return text\n",
        "        else:\n",
        "            # 🧾 Fallback to OCR\n",
        "            images = convert_from_path(file_path, dpi=200)\n",
        "            ocr_text = \"\\n\".join([pytesseract.image_to_string(img) for img in images])\n",
        "            return ocr_text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"ERROR in PDF: {e}\"\n",
        "\n",
        "# 📄 DOCX extractor\n",
        "def extract_text_from_docx(file_path):\n",
        "    try:\n",
        "        return docx2txt.process(file_path).strip()\n",
        "    except Exception as e:\n",
        "        return f\"ERROR in DOCX: {e}\"\n",
        "\n",
        "# 📦 Unified file processor\n",
        "def process_file(file_path):\n",
        "    try:\n",
        "        if file_path.lower().endswith(\".pdf\"):\n",
        "            return file_path, extract_text_from_pdf(file_path)\n",
        "        elif file_path.lower().endswith(\".docx\"):\n",
        "            return file_path, extract_text_from_docx(file_path)\n",
        "        else:\n",
        "            return file_path, \"Unsupported file type\"\n",
        "    except Exception as e:\n",
        "        return file_path, f\"ERROR in file: {e}\"\n",
        "\n",
        "# 🗂️ Collect files\n",
        "file_list = []\n",
        "for root, _, files in os.walk(attachments_folder):\n",
        "    for name in files:\n",
        "        if name.lower().endswith((\".pdf\", \".docx\")):\n",
        "            file_list.append(os.path.join(root, name))\n",
        "\n",
        "print(f\"📦 Total files found: {len(file_list)}\")\n",
        "\n",
        "# ⚡ Safe parallel execution with timeout + checkpointing\n",
        "results = []\n",
        "timeout_secs = 180  # 3 minutes max per file\n",
        "\n",
        "batch_size = 500\n",
        "for batch_idx in range(0, len(file_list), batch_size):\n",
        "    batch = file_list[batch_idx:batch_idx + batch_size]\n",
        "    print(f\"🚀 Processing batch {batch_idx//batch_size + 1}\")\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=6) as executor:\n",
        "        futures = {executor.submit(process_file, f): f for f in batch}\n",
        "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "            file = futures[future]\n",
        "            try:\n",
        "                result = future.result(timeout=timeout_secs)\n",
        "            except TimeoutError:\n",
        "                result = (file, \"ERROR: Timeout\")\n",
        "            except Exception as e:\n",
        "                result = (file, f\"ERROR: {e}\")\n",
        "            results.append(result)\n",
        "\n",
        "    # 💾 Save intermediate checkpoint\n",
        "    pd.DataFrame(results, columns=[\"filename\", \"text\"]).to_csv(checkpoint_file, index=False)\n",
        "    print(f\"💾 Checkpoint saved for batch {batch_idx//batch_size + 1}\")\n",
        "\n",
        "# ✅ Final export\n",
        "df = pd.DataFrame(results, columns=[\"filename\", \"text\"])\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"✅ Extraction complete. Final CSV saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4PGIbqoso8If",
      "metadata": {
        "id": "4PGIbqoso8If"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}