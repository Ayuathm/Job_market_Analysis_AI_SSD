{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "66065d5f",
      "metadata": {
        "id": "66065d5f"
      },
      "source": [
        "# ðŸ§  Job Extraction Pipeline with Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb5762a8",
      "metadata": {
        "id": "eb5762a8"
      },
      "source": [
        "### ðŸ“¥ Step 1: Load libraries and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f879f40",
      "metadata": {
        "id": "1f879f40"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from dateutil import parser\n",
        "\n",
        "# Load the dataset\n",
        "# Replace with your actual file name if different\n",
        "df = pd.read_csv('extracted_job_texts.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eafb100",
      "metadata": {
        "id": "1eafb100"
      },
      "source": [
        "### ðŸ§¹ Step 2: Clean the raw text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97700f4f",
      "metadata": {
        "id": "97700f4f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'(CamScanner|Page\\s\\d+|\\s*@\\s*)', ' ', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII\n",
        "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Apply cleaning\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a0574c1",
      "metadata": {
        "id": "5a0574c1"
      },
      "source": [
        "### ðŸ“Œ Step 3: Define extraction functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbcc2226",
      "metadata": {
        "id": "fbcc2226"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_organization(text):\n",
        "    known_orgs = [\n",
        "        \"Save the Children\", \"ZOA\", \"UNICEF\", \"UNHCR\", \"WFP\", \"IRC\", \"CARE\", \"World Vision\", \"Medair\", \"ACTED\",\n",
        "        \"Plan International\", \"Danish Refugee Council\", \"Oxfam\", \"CAFOD\", \"Caritas\", \"ADRA\", \"Cordaid\",\n",
        "        \"Concern Worldwide\", \"Norwegian Refugee Council\", \"CTG\", \"GOAL\", \"GIZ\", \"Mercy Corps\", \"INTERSOS\",\n",
        "        \"Catholic Relief Services\", \"UNDP\", \"FAO\", \"WHO\", \"MSF\", \"IOM\", \"ACF\", \"War Child\"\n",
        "    ]\n",
        "    lines = text.strip().split('\\n')[:30]\n",
        "    for line in lines:\n",
        "        for org in known_orgs:\n",
        "            if org.lower() in line.lower():\n",
        "                return org\n",
        "    for line in lines:\n",
        "        match = re.search(r'(Organization|Published by|By|Employer)[:\\-]?\\s*([A-Z][A-Za-z &,.]{3,})', line)\n",
        "        if match:\n",
        "            candidate = match.group(2).strip()\n",
        "            if not re.search(r'\\d', candidate) and len(candidate.split()) <= 6:\n",
        "                return candidate\n",
        "    for line in lines:\n",
        "        if 2 <= len(line.split()) <= 5 and line.istitle() and not re.search(r'\\d', line):\n",
        "            return line.strip()\n",
        "    return \"Unknown\"\n",
        "\n",
        "def extract_job_title(text):\n",
        "    lines = text.strip().split('\\n')[:30]\n",
        "    patterns = [\n",
        "        r'(job title|position|title|vacancy)[:\\-]?\\s*(.+)',\n",
        "        r'we are looking for[:\\-]?\\s*(.+)',\n",
        "        r'role[:\\-]?\\s*(.+)',\n",
        "        r'job opening[:\\-]?\\s*(.+)',\n",
        "        r'recruiting[:\\-]?\\s*(.+)'\n",
        "    ]\n",
        "    for line in lines:\n",
        "        for pattern in patterns:\n",
        "            match = re.search(pattern, line, re.IGNORECASE)\n",
        "            if match:\n",
        "                title = match.group(2).strip()\n",
        "                title = re.sub(r'[^a-zA-Z0-9 \\-_/()]', '', title)\n",
        "                if 3 < len(title) < 100:\n",
        "                    return title\n",
        "    return \"Unknown\"\n",
        "\n",
        "def extract_skills(text):\n",
        "    keywords = [\n",
        "        \"python\", \"java\", \"excel\", \"word\", \"powerpoint\", \"sql\", \"r\", \"gis\", \"arcgis\",\n",
        "        \"monitoring\", \"evaluation\", \"communication\", \"leadership\", \"report writing\",\n",
        "        \"project management\", \"budgeting\", \"data analysis\", \"problem solving\", \"teamwork\",\n",
        "        \"procurement\", \"logistics\", \"negotiation\", \"networking\", \"supervision\",\n",
        "        \"customer service\", \"human resources\", \"training\", \"coaching\", \"facilitation\",\n",
        "        \"presentation\", \"graphic design\", \"research\", \"documentation\", \"compliance\"\n",
        "    ]\n",
        "    found = sorted(set([kw for kw in keywords if re.search(rf'\\\\b{kw}\\\\b', text, re.IGNORECASE)]))\n",
        "    return \", \".join(found) if found else \"Not Found\"\n",
        "\n",
        "def extract_sector(text):\n",
        "    sectors = {\n",
        "        \"Education\": [\"school\", \"education\", \"teacher\", \"training\"],\n",
        "        \"Health\": [\"health\", \"clinic\", \"medical\", \"nutrition\", \"hiv\", \"malaria\"],\n",
        "        \"Humanitarian\": [\"ngo\", \"unicef\", \"humanitarian\", \"relief\", \"emergency\", \"refugee\"],\n",
        "        \"Agriculture\": [\"farm\", \"agriculture\", \"livestock\", \"crop\"],\n",
        "        \"Logistics\": [\"logistics\", \"transport\", \"fleet\", \"supply chain\"],\n",
        "        \"Finance\": [\"finance\", \"accounting\", \"audit\", \"budget\", \"grants\", \"payroll\"],\n",
        "        \"WASH\": [\"water\", \"sanitation\", \"hygiene\"],\n",
        "        \"Protection\": [\"protection\", \"gender\", \"child protection\", \"gbv\"],\n",
        "        \"ICT\": [\"ict\", \"information technology\", \"systems\", \"database\", \"network\"]\n",
        "    }\n",
        "    for sector, keywords in sectors.items():\n",
        "        for kw in keywords:\n",
        "            if re.search(rf'\\\\b{kw}\\\\b', text, re.IGNORECASE):\n",
        "                return sector\n",
        "    return \"Unknown\"\n",
        "\n",
        "def extract_location(text):\n",
        "    known_places = [\n",
        "        \"Juba\", \"Wau\", \"Malakal\", \"Bor\", \"Yambio\", \"Rumbek\", \"Aweil\", \"Yei\", \"Torit\",\n",
        "        \"Bentiu\", \"Terekeeka\", \"Kapoeta\", \"Maridi\", \"Tonj\", \"Abyei\", \"Pibor\", \"Akobo\",\n",
        "        \"Leer\", \"Renk\", \"Kodok\", \"Paloich\", \"Tali\", \"Magwi\", \"Koch\", \"Pariang\"\n",
        "    ]\n",
        "    for place in known_places:\n",
        "        if re.search(rf'\\\\b{place}\\\\b', text, re.IGNORECASE):\n",
        "            return place\n",
        "    match = re.search(r'(location|duty station|based in|workplace)[:\\-]?\\s*([^\\n\\r\\.,]+)', text, re.IGNORECASE)\n",
        "    return match.group(2).strip() if match else \"Unknown\"\n",
        "\n",
        "def extract_posting_date(text):\n",
        "    patterns = [\n",
        "        r'\\b(\\d{1,2}\\s+\\w+\\s+\\d{4})\\b',\n",
        "        r'\\b(\\w+\\s+\\d{1,2},\\s+\\d{4})\\b',\n",
        "        r'\\b(\\d{4}-\\d{2}-\\d{2})\\b'\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "    return \"Unknown\"\n",
        "\n",
        "def normalize_date(date_str):\n",
        "    try:\n",
        "        return parser.parse(date_str, fuzzy=True, dayfirst=True).strftime(\"%Y-%m-%d\")\n",
        "    except:\n",
        "        return \"Unknown\"\n",
        "\n",
        "def classify_job_type(text):\n",
        "    job_types = {\n",
        "        \"Full-time\": [\"full time\", \"permanent\", \"long-term\", \"staff position\"],\n",
        "        \"Part-time\": [\"part time\", \"temporary\", \"short-term\", \"casual\"],\n",
        "        \"Consultancy\": [\"consultant\", \"consultancy\", \"contract basis\", \"individual contractor\"],\n",
        "        \"Internship\": [\"intern\", \"internship\", \"trainee\"],\n",
        "        \"Volunteer\": [\"volunteer\", \"voluntary service\"]\n",
        "    }\n",
        "    for jtype, keywords in job_types.items():\n",
        "        for kw in keywords:\n",
        "            if re.search(rf'\\\\b{kw}\\\\b', text, re.IGNORECASE):\n",
        "                return jtype\n",
        "    return \"Unclassified\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b2dc5af",
      "metadata": {
        "id": "7b2dc5af"
      },
      "source": [
        "### ðŸ”Ž Step 4: Apply extraction to the cleaned text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39318ef1",
      "metadata": {
        "id": "39318ef1"
      },
      "outputs": [],
      "source": [
        "\n",
        "df[\"organization\"] = df[\"cleaned_text\"].apply(extract_organization)\n",
        "df[\"job_title\"] = df[\"cleaned_text\"].apply(extract_job_title)\n",
        "df[\"skills\"] = df[\"cleaned_text\"].apply(extract_skills)\n",
        "df[\"sector\"] = df[\"cleaned_text\"].apply(extract_sector)\n",
        "df[\"location\"] = df[\"cleaned_text\"].apply(extract_location)\n",
        "df[\"posting_date\"] = df[\"cleaned_text\"].apply(extract_posting_date).apply(normalize_date)\n",
        "df[\"job_type\"] = df[\"cleaned_text\"].apply(classify_job_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60d8085",
      "metadata": {
        "id": "a60d8085"
      },
      "source": [
        "### ðŸ’¾ Step 5: Export cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06671163",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06671163",
        "outputId": "e8602835-de67-48b4-de8c-a065bcda76cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "output = df[[\n",
        "    \"filename\", \"organization\", \"job_title\", \"skills\", \"sector\",\n",
        "    \"location\", \"posting_date\", \"job_type\"\n",
        "]]\n",
        "output.to_csv(\"final_cleaned_job_output.csv\", index=False)\n",
        "print(\"Export complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cQLB591CG9Ab"
      },
      "id": "cQLB591CG9Ab",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}